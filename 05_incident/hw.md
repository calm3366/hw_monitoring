### Краткое описание инцидента 
Из-за потери соединения между сетевым узлом на восточном побережье и основным ЦОД на 43 секунды стали недоступны некоторые сервисы, появление непоследовательной информации на веб-сайте
### Предшествующие события
Плановые работы по техническому обслуживанию по замене неисправного оптического оборудования 100G
### Причина инцидента
Потеря соединения между сетевым узлом на восточном побережье и основным ЦОД на 43 секунды
### Воздействие
Ухудшению качества обслуживания на 24 часа и 11 минут. Этот инцидент не затронул некоторые части нашей платформы, но были затронуты несколько внутренних систем, в результате чего мы отображали устаревшую и непоследовательную информацию
### Обнаружение
Система мониторинга
### Реакция
Ответственные лица устранили инцидент за 24 часа и 11 минут
### Восстановление
Восстановление БД из резервных копий, синхронизация реплик на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновление обработок заданий в очереди
### Таймлайн
21.10.2018 

21:52 серверы баз данных в центре обработки данных на восточном побережье США содержали короткий период записей, которые не были реплицированы на объект на западном побережье США

22:54 истемы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои в наших системах

23:02 инженеры нашей группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в неожиданном состоянии. Запрос к API Orchestrator показал топологию репликации базы данных, которая включала только серверы из нашего центра обработки данных на западном побережье США

23:07 группа реагирования решила вручную заблокировать наши внутренние инструменты развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений

23:09 группа реагирования перевела сайт в желтый статус. Это действие автоматически перевело ситуацию в активный инцидент и отправило предупреждение координатору инцидента

23:11 подключился координатор инцидентов и через две минуты изменил статус решения на красный

23:13 проблема затронула несколько кластеров баз данных. Были вызваны дополнительные инженеры из группы разработки баз данных GitHub. Они начали исследовать текущее состояние, чтобы определить, какие действия необходимо предпринять, чтобы вручную настроить базу данных Восточного побережья США в качестве основной для каждого кластера и перестроить топологию репликации

23:19 После запроса состояния кластеров базы данных стало ясно, что нам нужно остановить выполнение заданий, записывающих метаданные о таких вещах, как push-уведомления. Мы сделали явный выбор частично снизить удобство использования сайта, приостановив доставку веб-перехватчиков и сборку страниц GitHub вместо того, чтобы поставить под угрозу данные, которые мы уже получили от пользователей

22.10.2018 

00:05 Инженеры, участвующие в группе реагирования на инциденты, начали разработку плана по устранению несоответствий данных и реализации наших процедур аварийного переключения для MySQL. Мы обновили свой статус , чтобы сообщить пользователям, что мы собираемся выполнить контролируемый переход на другой ресурс внутренней системы хранения данных. Процесс распаковки, подсчета контрольной суммы, подготовки и загрузки больших файлов резервных копий на вновь подготовленные серверы MySQL занял большую часть времени

00:41 К этому времени был начат процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры следили за ходом его выполнения. Одновременно несколько групп инженеров искали способы ускорить передачу и восстановление без дальнейшего ухудшения удобства использования сайта или риска повреждения данных

06:51 Несколько кластеров завершили восстановление из резервных копий в нашем центре обработки данных на восточном побережье США и начали репликацию новых данных с западного побережья. Это приводило к медленной загрузке сайта для страниц, которым приходилось выполнять операцию записи по межстрановой ссылке, но страницы, читающие из этих кластеров баз данных, возвращали актуальные результаты, если запрос на чтение попадал на недавно восстановленную реплику. Другие более крупные кластеры баз данных все еще восстанавливались

07:46 GitHub опубликовал сообщение в блоге , чтобы предоставить больше контекста

11:12 Все первичные базы данных снова установлены на восточном побережье США. В результате сайт стал гораздо более отзывчивым. Несмотря на существенное повышение производительности, десятки реплик чтения базы данных по-прежнему отставали от основной на несколько часов. Эти отложенные реплики привели к тому, что пользователи видели противоречивые данные при взаимодействии с нашими сервисами

13:15 К этому моменту приближался к пиковой нагрузке трафик на GitHub.com. Как только дополнительные реплики чтения MySQL стали доступны, стало проще распределить объем запросов на чтение между большим количеством серверов

16:24 Как только реплики были синхронизированы, мы выполнили переход на исходную топологию, решая непосредственные проблемы с задержкой и доступностью

16:45 Пришлось сбалансировать возросшую нагрузку, связанную с отставанием, потенциально перегружая наших партнеров по экосистеме уведомлениями, и как можно быстрее вернуть наши услуги на 100%. Чтобы избежать дальнейшего снижения надежности наших обновлений статуса, мы оставались в пониженном статусе до тех пор, пока не завершили обработку всего накопившегося массива данных и не убедились, что наши услуги четко вернулись к нормальному уровню производительности

23:03 Все ожидающие сборки веб-перехватчиков и страниц были обработаны, а целостность и правильная работа всех систем подтверждены. Статус сайта изменился на зеленый

### Последующие действия
1 - Настройте конфигурацию Orchestrator, чтобы предотвратить распространение основных баз данных за пределы региональных границ.

2 - Переход на новый механизм отчетности о статусе, который предоставит нам более обширную площадку для обсуждения активных инцидентов более четким и понятным языком

3 - Поддержка обслуживания трафика GitHub из нескольких центров обработки данных в схеме «активный-активный-активный». Целью этого проекта является поддержка резервирования N+1 на уровне объекта. Цель этой работы — выдержать полный отказ одного центра обработки данных без воздействия на пользователя